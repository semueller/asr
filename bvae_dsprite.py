from asr.bvae import  bVAE, ConvDecoder, ConvEncoder
from asr.util import save_model, load_model, check_for_gpu
import torch
import torch.nn.functional as F
import numpy as np
import pickle as pkl

def main(save_prefix='./model'):
    # Load dataset
    dataset_zip = np.load('./data/test/dsprites.npz')
    imgs = dataset_zip['imgs']
    imgs = np.expand_dims(imgs, 1)
    num_imgs = len(imgs)
    idxs = np.arange(num_imgs)
    np.random.shuffle(idxs)
    train_perc = 0.8
    train_idxs, test_idxs = idxs[:int(train_perc*num_imgs)], idxs[int(train_perc*num_imgs):]
    with open(save_prefix+'/shuffle_idxs.pkl', 'wb') as f:
        pkl.dump({'train':train_idxs, 'test': test_idxs}, f)
    x_train, x_test = imgs[train_idxs], imgs[test_idxs]

    latent_dim = 9  # datastet was generated by 6 latent features, we want to see that 3 dimensions are unused
    data_shape = (1, 64, 64)
    encoder = ConvEncoder(in_shape=data_shape, out_dim=latent_dim)  # out_dim == dim of mu and dim of log_var
    decoder = ConvDecoder(in_dim=latent_dim, out_shape=data_shape, )
    print(encoder.extra_repr())
    print(decoder.extra_repr())

    print("build beta vae")

    device = check_for_gpu()
    x_train = x_train/255
    if device.type == 'cuda':
        print('data to {}'.format(device))
        x_train = torch.tensor(x_train).to(device)
    else:
        x_train = torch.tensor(x_train).to(torch.float64)

    l = F.binary_cross_entropy
    # l = F.hinge_embedding_loss
    bvae = bVAE(encoder, decoder, latent_dim=latent_dim, recon_loss=l)
    bvae.to(device)
    print(bvae.extra_repr())

    print("fit bvae")
    history = bvae.fit(x_train, x_train, n_epochs=100, batch_size=128)

    print("saving model")
    path = save_prefix
    modelname = 'bvae_dsprite'
    save_model(bvae, path=path, modelname=modelname)

if __name__=='__main__':
    prefix = '/dev/shm/semueller/asr/'
    main(save_prefix = prefix)
